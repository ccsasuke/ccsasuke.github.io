<!doctype html>
<html lang="en-US">
  <head>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-EWDTP9LQX7"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-EWDTP9LQX7');
    </script>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" href="assets/css/style.css?v=">
    <link rel="stylesheet" href="assets/css/fontawesome.min.css"/>
    <link rel="stylesheet" href="assets/css/brands.min.css"/>
    <link rel="stylesheet" href="assets/css/solid.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <meta name="viewport" content="width=device-width">

    <title>Xilun Chen's Homepage</title>
  </head>
  <body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WZQG483"
                    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
    <div class="wrapper">
      <header>
        <div id="avatar-container">
            <img src="assets/images/avatar.png" alt="Avatar" height="200" width="200">
        </div>
        <a href=""> <h1>Xilun Chen</h1> </a>
        <p id="intro">
I am a Research Scientist at <a href="https://ai.meta.com/research" target="_blank">Fundamental AI Research (FAIR), Meta</a>. I obtained my PhD in Computer Science from <a href="https://www.cs.cornell.edu/" target="_blank">Cornell University</a> in 2019.
My advisor was<wbr> <a href="http://www.cs.cornell.edu/home/cardie/" target="_blank">Prof. Claire Cardie</a>.
Before that, I did my undergraduate study at Shanghai Jiao Tong University.
        </p>

        <p><span style="font-size: 1em;"><i class="fa-solid fa-lg fa-location-dot"></i> Seattle, WA</span></p>
        <p><a href="https://scholar.google.com/citations?hl=en&user=eUk_hy8AAAAJ&sortby=pubdate" target="_blank"><i style="font-size:1.3em;" class="ai ai-lg ai-google-scholar"></i> Google Scholar</a></p>
        <p><a href="https://github.com/ccsasuke" target="_blank"><span style="font-size: 1em; color: #171516;"><i class="fa-brands fa-lg fa-github"></i> @ccsasuke</span></a></p>
        <p><a href="https://twitter.com/ccsasuke" target="_blank"><span style="font-size: 1em; color: #55acee;"><i class="fa-brands fa-lg fa-twitter"></i> @ccsasuke</span></a></p>
          <p><i class="fa-solid fa-lg fa-envelope"></i> xilun@<span class="displaynone">nospam.</span>meta.com (work)</br>
          <i class="fa-solid fa-lg fa-envelope"></i> xlchen@<span class="displaynone">nospam.</span>cs.cornell.edu (personal)</p>

	<p>(Last updated: Jun 2024)</p>

      </header>
      <section>

      <h1 id="research"><a href="#research">Research</a></h1>
<p>My research interests lie broadly in Natural Language Processing and Machine Learning. I am particularly intrigued by the interplay between knowledge and language.
In recent years, I have been working on knowledge-intensive NLP problems such as Open-Domain Question Answering, Neural Retrieval, and more recently Retrieval-Augmented Language Models.</p>

<p>Previously, my PhD research was about learning deep representations for low-resource / zero-resource cross-lingual model transfer.</p>

<h1 id="publications"><a href="#publications">Publications</a></h1>
<p>(* denotes equal contribution)</p>

<h4 id="2024"><a href="#publications2024">2024</a></h4>

<p><strong>FLAMEðŸ”¥: Factuality-Aware Alignment for Large Language Models</strong><br />
Sheng-Chieh Lin*, Luyu Gao, Barlas Oguz, Wenhan Xiong, Jimmy Lin, Wen-tau Yih, <strong>Xilun Chen</strong>*<br />
Preprint<br />
<a href="https://arxiv.org/abs/2405.01525">arXiv</a></p>

<p><strong>Nearest Neighbor Speculative Decoding for LLM Generation and Attribution</strong><br />
Minghan Li, <strong>Xilun Chen</strong>, Ari Holtzman, Beidi Chen, Jimmy Lin, Wen-tau Yih, Xi Victoria Lin<br />
Preprint<br />
<a href="https://arxiv.org/abs/2405.19325">arXiv</a></p>

<p><strong>An Introduction to Vision-Language Modeling</strong><br />
Florian Bordes, Richard Yuanzhe Pang, Anurag Ajay, Alexander C. Li, Adrien Bardes, Suzanne Petryk, Oscar MaÃ±as, Zhiqiu Lin, Anas Mahmoud, Bargav Jayaraman, Mark Ibrahim, Melissa Hall, Yunyang Xiong, Jonathan Lebensold, Candace Ross, Srihari Jayakumar, Chuan Guo, Diane Bouchacourt, Haider Al-Tahan, Karthik Padthe, Vasu Sharma, Hu Xu, Xiaoqing Ellen Tan, Megan Richards, Samuel Lavoie, Pietro Astolfi, Reyhane Askari Hemmat, Jun Chen, Kushal Tirumala, Rim Assouel, Mazda Moayeri, Arjang Talattof, Kamalika Chaudhuri, Zechun Liu, <strong>Xilun Chen</strong>, Quentin Garrido, Karen Ullrich, Aishwarya Agrawal, Kate Saenko, Asli Celikyilmaz, Vikas Chandra<br />
Preprint<br />
<a href="https://arxiv.org/abs/2405.17247">arXiv</a></p>

<p><strong>Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning</strong><br />
Rao Fu, Jingyu Liu, <strong>Xilun Chen</strong>, Yixin Nie, Wenhan Xiong<br />
Preprint<br />
<a href="https://arxiv.org/abs/2403.11401">arXiv</a></p>

<p><strong>RA-DIT: Retrieval-Augmented Dual Instruction Tuning</strong><br />
Xi Victoria Lin*, <strong>Xilun Chen</strong>*, Mingda Chen*, Weijia Shi, Maria Lomeli, Rich James, Pedro Rodriguez, Jacob Kahn, Gergely Szilvasy, Mike Lewis, Luke Zettlemoyer and Scott Wen-tau Yih<br />
ICLR 2024<br />
<a href="https://openreview.net/forum?id=22OTbutug9">proceedings</a>,
<a href="https://arxiv.org/abs/2310.01352">arXiv</a></p>

<p><strong>Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis</strong><br />
Mingda Chen, <strong>Xilun Chen</strong> and Scott Wen-tau Yih<br />
EACL 2024<br />
<a href="https://aclanthology.org/2024.eacl-long.12/">proceedings</a>,
<a href="https://arxiv.org/abs/2305.13691">arXiv</a></p>

<h4 id="2023"><a href="#publications2023">2023</a></h4>

<p><strong>VideoOFA: Two-Stage Pre-Training for Video-to-Text Generation</strong><br />
<strong>Xilun Chen</strong>, Lili Yu, Wenhan Xiong, Barlas OÄŸuz, Yashar Mehdad, Scott Wen-tau Yih<br />
arXiv 2305.03204<br />
<a href="https://arxiv.org/abs/2305.03204">arXiv</a></p>

<p><strong>How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval</strong><br />
Sheng-Chieh Lin*, Akari Asai, Minghan Li, Barlas Oguz, Jimmy Lin, Yashar Mehdad, Scott Wen-tau Yih, <strong>Xilun Chen</strong>*<br />
Findings of EMNLP 2023<br />
<a href="https://aclanthology.org/2023.findings-emnlp.423/">proceedings</a>,
<a href="https://arxiv.org/abs/2302.07452">arXiv</a>,
<a href="https://github.com/facebookresearch/dpr-scale/tree/main/dragon">code</a>,
<a href="https://huggingface.co/facebook/dragon-plus-query-encoder">huggingface</a></p>

<p><strong>CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for Efficient and Effective Multi-Vector Retrieval</strong><br />
Minghan Li*, Sheng-Chieh Lin, Barlas Oguz, Asish Ghoshal, Jimmy Lin, Yashar Mehdad, Scott Wen-tau Yih, <strong>Xilun Chen</strong>*<br />
ACL 2023 (Oral)<br />
<a href="https://aclanthology.org/2023.acl-long.663/">proceedings</a>,
<a href="https://arxiv.org/abs/2211.10411">arXiv</a>,
<a href="https://github.com/facebookresearch/dpr-scale/tree/citadel">code</a></p>

<p><strong>Nonparametric Masked Language Modeling</strong><br />
Sewon Min, Weijia Shi, Mike Lewis, <strong>Xilun Chen</strong>, Scott Wen-tau Yih, Hannaneh Hajishirzi, Luke Zettlemoyer<br />
Findings of ACL 2023<br />
<a href="https://aclanthology.org/2023.findings-acl.132/">proceedings</a>,
<a href="https://arxiv.org/abs/2212.01349">arXiv</a>,
<a href="https://github.com/facebookresearch/NPM">code</a></p>

<p><strong>Task-aware Retrieval with Instructions</strong><br />
Akari Asai, Timo Schick, Patrick Lewis, <strong>Xilun Chen</strong>, Gautier Izacard, Sebastian Riedel, Hannaneh Hajishirzi, Scott Wen-tau Yih<br />
Findings of ACL 2023<br />
<a href="https://aclanthology.org/2023.findings-acl.225/">proceedings</a>,
<a href="https://arxiv.org/abs/2211.09260">arXiv</a>,
<a href="https://github.com/facebookresearch/tart">code</a></p>

<p><strong>A Study on the Efficiency and Generalization of Light Hybrid Retrievers</strong><br />
Man Luo, Shashank Jain, Anchit Gupta, Arash Einolghozati, Barlas Oguz, Debojeet Chatterjee, <strong>Xilun Chen</strong>, Chitta Baral, Peyman Heidari<br />
ACL 2023 (short)<br />
<a href="https://aclanthology.org/2023.acl-short.139/">proceedings</a>,
<a href="https://arxiv.org/abs/2210.01371">arXiv</a></p>

<p><strong>Hierarchical Video-Moment Retrieval and Step-Captioning</strong><br />
Abhay Zala*, Jaemin Cho*, Satwik Kottur, <strong>Xilun Chen</strong>, Barlas Oguz, Yashar Mehdad, Mohit Bansal<br />
CVPR 2023<br />
<a href="https://hirest-cvpr2023.github.io/">project page</a>,
<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Zala_Hierarchical_Video-Moment_Retrieval_and_Step-Captioning_CVPR_2023_paper.html">proceedings</a>,
<a href="https://arxiv.org/abs/2303.16406">arXiv</a>,
<a href="https://github.com/j-min/HiREST">code</a></p>

<h4 id="2022"><a href="#publications2022">2022</a></h4>

<p><strong>Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?</strong><br />
<strong>Xilun Chen</strong>, Kushal Lakhotia, Barlas Oguz, Anchit Gupta, Patrick Lewis, Stan Peshterliev, Yashar Mehdad, Sonal Gupta, Scott Wen-tau Yih<br />
Findings of EMNLP 2022<br />
<a href="https://aclanthology.org/2022.findings-emnlp.19/">proceedings</a>,
<a href="https://arxiv.org/abs/2110.06918">arXiv</a>,
<a href="https://github.com/facebookresearch/dpr-scale/tree/main/spar">code</a></p>

<p><strong>Simple Local Attentions Remain Competitive for Long-Context Tasks</strong><br />
Wenhan Xiong, Barlas Oguz, Anchit Gupta, <strong>Xilun Chen</strong>, Diana Liskovich, Omer Levy, Scott Yih, Yashar Mehdad<br />
NAACL-HLT 2022<br />
<a href="https://aclanthology.org/2022.naacl-main.144/">proceedings</a>,
<a href="https://arxiv.org/abs/2112.07210">arXiv</a>,
<a href="https://github.com/facebookresearch/fairseq/tree/main/examples/xformers">code</a></p>

<p><strong>CCQA: A New Web-Scale Question Answering Dataset for Model Pre-Training</strong><br />
Patrick Huber, Armen Aghajanyan, Barlas OÄŸuz, Dmytro Okhonko, Wen-tau Yih, Sonal Gupta, <strong>Xilun Chen</strong><br />
Findings of NAACL-HLT 2022<br />
<a href="https://aclanthology.org/2022.findings-naacl.184/">proceedings</a>,
<a href="https://arxiv.org/abs/2110.07731">arXiv</a>,
<a href="https://github.com/facebookresearch/ccqa">code</a></p>

<p><strong>Domain-matched Pre-training Tasks for Dense Retrieval</strong><br />
Barlas Oguz*, Kushal Lakhotia*, Anchit Gupta*, Patrick Lewis, Vladimir Karpukhin, Aleksandra Piktus, <strong>Xilun Chen</strong>, Sebastian Riedel, Scott Yih, Sonal Gupta, Yashar Mehdad<br />
Findings of NAACL-HLT 2022<br />
<a href="https://aclanthology.org/2022.findings-naacl.114/">proceedings</a>,
<a href="https://arxiv.org/abs/2107.13602">arXiv</a>,
<a href="https://github.com/facebookresearch/dpr-scale">code</a></p>

<p><strong>UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering</strong><br />
Barlas Oguz*, <strong>Xilun Chen</strong>*, Vladimir Karpukhin, Stan Peshterliev, Dmytro Okhonko, Michael Schlichtkrull, Sonal Gupta, Yashar Mehdad, Scott Yih<br />
Findings of NAACL-HLT 2022<br />
<a href="https://aclanthology.org/2022.findings-naacl.115/">proceedings</a>,
<a href="https://arxiv.org/abs/2012.14610">arXiv</a>,
<a href="https://github.com/facebookresearch/UniK-QA">code</a></p>

<h4 id="2021"><a href="#publications2021">2021</a></h4>

<p><strong>Muppet: Massive Multi-task Representations with Pre-Finetuning</strong><br />
Armen Aghajanyan, Anchit Gupta, Akshat Shrivastava, <strong>Xilun Chen</strong>, Luke Zettlemoyer, Sonal Gupta<br />
EMNLP 2021<br />
<a href="https://aclanthology.org/2021.emnlp-main.468/">proceedings</a>,
<a href="https://arxiv.org/abs/2101.11038">arXiv</a>,
<a href="https://huggingface.co/facebook/muppet-roberta-base">huggingface</a></p>

<p><strong>Learning Better Structured Representations Using Low-rank Adaptive Label Smoothing</strong><br />
Asish Ghoshal, <strong>Xilun Chen</strong>, Sonal Gupta, Luke Zettlemoyer, Yashar Mehdad<br />
ICLR 2021<br />
<a href="https://openreview.net/forum?id=5NsEIflpbSv">proceedings</a></p>

<p><strong>NeurIPS 2020 EfficientQA Competition: Systems, Analyses and Lessons Learned</strong><br />
Sewon Min, Jordan Boyd-Graber, Chris Alberti, Danqi Chen, Eunsol Choi, Michael Collins, Kelvin Guu, Hannaneh Hajishirzi, Kenton Lee, Jennimaria Palomaki, Colin Raffel, Adam Roberts, Tom Kwiatkowski, Patrick Lewis, Yuxiang Wu, Heinrich KÃ¼ttler, Linqing Liu, Pasquale Minervini, Pontus Stenetorp, Sebastian Riedel, Sohee Yang, Minjoon Seo, Gautier Izacard, Fabio Petroni, Lucas Hosseini, Nicola De Cao, Edouard Grave, Ikuya Yamada, Sonse Shimaoka, Masatoshi Suzuki, Shumpei Miyawaki, Shun Sato, Ryo Takahashi, Jun Suzuki, Martin Fajcik, Martin Docekal, Karel Ondrej, Pavel Smrz, Hao Cheng, Yelong Shen, Xiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao, Barlas Oguz, <strong>Xilun Chen</strong>, Vladimir Karpukhin, Stan Peshterliev, Dmytro Okhonko, Michael Schlichtkrull, Sonal Gupta, Yashar Mehdad, Wen-tau Yih<br />
Proceedings of Machine Learning Research<br />
<a href="https://efficientqa.github.io/">competition page</a>,
<a href="https://proceedings.mlr.press/v133/min21a.html">proceedings</a>,
<a href="https://arxiv.org/abs/2101.00133">arXiv</a></p>

<h4 id="2020"><a href="#publications2020">2020</a></h4>

<p><strong>Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing</strong><br />
<strong>Xilun Chen</strong>, Asish Ghoshal, Yashar Mehdad, Luke Zettlemoyer, Sonal Gupta<br />
EMNLP 2020<br />
<a href="https://aclanthology.org/2020.emnlp-main.413/">proceedings</a>,
<a href="https://arxiv.org/abs/2010.03546">arXiv</a>,
<a href="https://fb.me/TOPv2Dataset">data</a></p>

<h4 id="2019"><a href="#publications2019">2019</a></h4>
<p><strong>Learning Deep Representations for Low-Resource Cross-Lingual Natural Language Processing</strong><br />
<strong>Xilun Chen</strong><br />
<strong>PhD Dissertation</strong>, Cornell University, May, 2019<br />
<a href="resources/papers/xilun_dissertation.pdf">pdf</a></p>

<p><strong>Multi-Source Cross-Lingual Model Transfer: Learning What to Share</strong><br />
<strong>Xilun Chen</strong>, Ahmed Hassan Awadallah, Hany Hassan, Wei Wang and Claire Cardie<br />
Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (<strong>ACL 2019</strong>)<br />
<a href="https://www.aclweb.org/anthology/P19-1299">proceedings</a>,
<a href="https://aclweb.org/anthology/papers/P/P19/P19-1299.bib">bibtex</a>,
<a href="https://arxiv.org/abs/1810.03552">arXiv</a>,
<a href="https://github.com/microsoft/Multilingual-Model-Transfer">code</a></p>

<h4 id="2018"><a href="#publications2018">2018</a></h4>

<p><strong>Unsupervised Multilingual Word Embeddings</strong><br />
<strong>Xilun Chen</strong>, Claire Cardie<br />
Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP 2018</strong>)<br />
<a href="http://aclweb.org/anthology/D18-1024">proceedings</a>,
<a href="http://aclweb.org/anthology/D18-1024.bib">bibtex</a>,
<a href="https://arxiv.org/abs/1808.08933">arXiv</a>,
<a href="resources/posters/umwe.pdf">poster</a>,
<a href="https://github.com/ccsasuke/umwe">code</a></p>

<p><strong>Multinomial Adversarial Networks for Multi-Domain Text Classification</strong><br />
<strong>Xilun Chen</strong>, Claire Cardie<br />
Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (<strong>NAACL-HLT 2018</strong>)<br />
<a href="http://aclweb.org/anthology/N18-1111">proceedings</a>,
<a href="http://aclweb.org/anthology/N18-1111.bib">bibtex</a>,
<a href="https://arxiv.org/abs/1802.05694">arXiv</a>,
<a href="resources/posters/man.pdf">poster</a>,
<a href="https://github.com/ccsasuke/man">code</a></p>

<p><strong>Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification</strong><br />
<strong>Xilun Chen</strong>, Yu Sun, Ben Athiwaratkun, Claire Cardie and Kilian Weinberger<br />
Transactions of the Association for Computational Linguistics (<strong>TACL</strong>). <br />
<a href="https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00039">Article</a>,
<a href="resources/bibtex/adan_tacl.bib">bibtex (TACL)</a>,
<a href="https://arxiv.org/abs/1606.01614">arXiv</a>,
<a href="resources/bibtex/adan.bib">bibtex (arXiv)</a>,
<a href="https://vimeo.com/306129914">talk@EMNLP2018</a>,
<a href="https://github.com/ccsasuke/adan">code</a></p>

<h4 id="2017-and-before"><a href="#publications2017">2017 and Before</a></h4>

<p><strong>A Rectangle Mining Method for Understanding the Semantics of Financial Tables</strong><br />
<strong>Xilun Chen</strong>, Laura Chiticariu, Marina Danilevsky, Alexandre Evfimievski and Prithviraj Sen<br />
The 14th IAPR International Conference on Document Analysis and Recognition (<strong>ICDAR 2017</strong>)<br />
<a href="http://ieeexplore.ieee.org/document/8269983/">proceedings</a>,
<a href="resources/papers/TableExtraction.pdf">pdf</a>,
<a href="resources/papers/poster_remine.pdf">poster</a>,
<a href="resources/bibtex/remine.bib">bibtex</a>,
<a href="resources/data/FinancialTableDataset.zip">dataset</a></p>

<p><strong>Combining Global Models for Parsing Universal Dependencies</strong><br />
Tianze Shi, Felix G. Wu, <strong>Xilun Chen</strong> and Yao Cheng<br />
Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies (<strong>CoNLL 2017</strong>)<br />
<a href="http://aclweb.org/anthology/K17-3003">pdf</a>, <a href="https://aclanthology.info/papers/K17-3003/k17-3003.bib">bibtex</a></p>

<p><strong>Price of Anarchy of Innovation Diffusion in Social Networks</strong><br />
<strong>Xilun Chen</strong> and Chenxia Wu, <strong>WINE 2014</strong> (Poster)<br />
<a href="https://arxiv.org/pdf/1407.7319.pdf">pdf</a></p>

<p><strong>Multi-Domain Adaptation for SMT Using Multi-Task Learning</strong><br />
Lei Cui, <strong>Xilun Chen</strong>, Dongdong Zhang, Shujie Liu,m Mu Li and Ming Zhou<br />
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP 2013</strong>)<br />
<a href="http://aclweb.org/anthology/D13-1107">pdf</a>, <a href="https://aclanthology.info/papers/D13-1107/d13-1107.bib">bibtex</a></p>

<h1 id="education-and-experiences"><a href="#experience">Education and Experiences</a></h1>
<p>2013 - 2019, Ph.D. in Computer Sciense, <strong>Cornell University</strong><br />
2009 - 2013, B.S.E. in Computer Sciense, <strong>Shanghai Jiao Tong University</strong><br /></p>

<p>08.2019 - present, Research Scientist at <strong>Meta AI</strong><br />
05.2018 - 08.2018, Research Intern at <strong>Microsoft Research</strong><br />
05.2017 - 08.2017, PhD Intern at <strong>Facebook</strong><br />
05.2016 - 08.2016, Research Intern at <strong>IBM Research</strong><br />
05.2015 - 08.2015, PhD Intern at <strong>Google</strong><br />
05.2012 - 02.2013, Undergrad Research Intern at <strong>Microsoft Research Asia</strong><br /></p>



      </section>
      <footer>
      </footer>
    </div>
    <script src="assets/js/scale.fix.js"></script>


  
    <script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
    <script type="text/javascript">
      $('.illustrations [data-toggle="tooltip"]').tooltip({
          animated: 'fade',
          html: true
      });
    </script>
  </body>
</html>
